{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nestornav/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correr una sola vez, para que la libería descargue las stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de Texto\n",
    "\n",
    "## Probemos algunas RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos algunos corpus sintécticos para hacer diferentes pruebas.\n",
    "\n",
    "txt_1 = \"\"\"\n",
    "Todos sabemos que el túnel que pasa bajo las vías en la estación Flores es una de las entradas del infierno.\n",
    "Cierta noche de otoño, el ruso Salzman, uno de los tahúres más prometedores del barrio,\n",
    "estaba haciendo un solitario en uno de los bares mugrientos que existen ahí.\n",
    "-Buenas noches, señor, soy el Diablo.\n",
    "Salzman saludó tímidamente. Estaba seguro de haber visto al Diablo otras veces, pero le pareció inadecuado mencionarlo.\n",
    "El hombre se acomodó en la silla y sonrió con dientes verdosos.\n",
    "\"\"\"\n",
    "\n",
    "txt_2 = \"\"\"\n",
    "esta Es una Prueba, enviada desde @lala.com para buscar el email: nestornav@gmail.com. La cuAL hemos TOMADO varios datos aleatorios de usuarios.\n",
    "Como documentos de identidad tales como 30210111 o sino también 32001200 y 32492005. Todo muy interesante. Gracias a nuestro mail mágico get_data@thief.com.\n",
    "Si desea desuscribirse de nuestro servicio marina.rodriguez2@gmail.com escriba a unsuscribe@lala.com.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es aplicar algunas funciones para analizar distintos comportamientos/resultados usando la librería de Python.\n",
    "\n",
    "A la hora de escribir Regex no existe una única forma para un mismo objetivo. Podemos llegar al mismo resultado muchas veces realizando distintas combinaciones.\n",
    "\n",
    "Brevemente dejo un explicación de algunos caracteres especiales más populares:\n",
    "* [ ]: filtra cualquier coincidencia.\n",
    "* [-]: filtra por medio de un rango.\n",
    "* [^a-z]: ^ es una negación, en este caso tenemos un ejemplo compuesto de lo anterior.\n",
    "* |: es un pipe o tubería, y al igual que unix nos sirve para concatenar la salida del paso previo y aplicar un nuevo tratamiento.\n",
    "* \\* : busca 0 o mas coincidencias previas a un caracter.\n",
    "* \\+ : busca 1 o mas coincidencias previas a un caracter.\n",
    "* $ : busca filtrar al final de una línea\n",
    "\n",
    "---\n",
    "\n",
    "Funciones de *re* a probar son:\n",
    "* sub\n",
    "* findall\n",
    "* split\n",
    "* search\n",
    "\n",
    "Para mas información la documentación de esta librería está [acá](https://docs.python.org/3/library/re.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(126, 132), match='otoño,'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Busquemos solo palabras\n",
    "re.search(r'\\w*,', txt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nestornav@gmail.com.',\n",
       " 'get_data@thief.com.',\n",
       " 'marina.rodriguez2@gmail.com',\n",
       " 'unsuscribe@lala.com.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos gustaría encontrar todos los mails en el documento que nos compartieron (txt_2)\n",
    "# Evaluemos como podemos generar expresiones equivalentes, y lleguemos a lo que queremos.\n",
    "re.findall(r'[\\w.-]+@[\\w.-]+',txt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(67, 87), match='nestornav@gmail.com.'>\n"
     ]
    }
   ],
   "source": [
    "#Encontremos ocurrencias dentro de los strings\n",
    "print(re.search( r'[\\w.-]+@[\\w.-]+', txt_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nesta Es una Prueba, enviada desde @lala.com para buscar el email: nestornav@gmail.com. La cuAL hemos TOMADO varios datos aleatorios de usuarios.\\nComo documentos de identidad tales como 30210111 o sino también 32001200 y 32492005. Todo muy interesante. Gracias a nuestro mail mágico get_data@thief.com.\\nSi desea desuscribirse de nuestro servicio marina.rodriguez2@gmail.com escriba a unsuscribe@lala.com.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como parte del proceso de normalización o adecuación, algunas veces nos resulta interesante reemplazar algunos tokens.\n",
    "re.sub(r' ',' ', txt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busquemos partir el texto en algo que nos resulte interesante para procesar.\n",
    "tokens = re.split(r' ',txt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentense = []\n",
    "with open('../works/data/don_quijote.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        sentense.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la A hasta la Z, como vos decís. Pues ese mismo abecedario pondréis vos en\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentense[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analicen que stop word hay por idioma\n",
    "stop_words_sp = stopwords.words('spanish')\n",
    "stop_words_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otras opciones para realizar esto mismo es usando diccionarios, o counter\n",
    "count = defaultdict(int)\n",
    "for sent in sentense:\n",
    "    for word in re.split(r' ',sent):\n",
    "        count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 tokens: [('que', 18240), ('de', 16636), ('y', 14708), ('la', 9245), ('a', 8906), ('en', 7400), ('el', 7309), ('\\n', 5931), ('no', 5258), ('se', 4309), ('los', 4194), ('con', 3769), ('', 3574), ('por', 3475), ('lo', 3167), ('las', 3097), ('le', 3053), ('su', 2975), ('don', 2345), ('del', 2251)]\n",
      "Tipos (V): 45703\n",
      "Tokens (N)): 393765\n"
     ]
    }
   ],
   "source": [
    "print('TOP 10 tokens:', sorted(count.items(), key=lambda x: -x[1])[:20])\n",
    "print('Tipos (V):', len(count))\n",
    "print('Tokens (N)):', sum(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiemos un poco el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acá solo estamos  filtrando una sola frase, que pasa si filtramos todo el quijote?\n",
    "tokens = [w for w in sentense[200].split() if not w in stop_words_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = defaultdict(int)\n",
    "for sent in tokens:\n",
    "    for word in re.split(r' ',sent):\n",
    "        count1[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos (V): 5\n",
      "Tokens (N)): 5\n"
     ]
    }
   ],
   "source": [
    "print('Tipos (V):', len(count1))\n",
    "print('Tokens (N)):', sum(count1.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sé que me los darían, y tales, que no les igualasen los de aquellos que\n",
      "\n",
      "TOP 10 tokens: [('sé', 1), ('darían,', 1), ('tales,', 1), ('igualasen', 1), ('aquellos', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(sentense[200])\n",
    "print('TOP 10 tokens:', sorted(count1.items(), key=lambda x: -x[1])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sé' in stop_words_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tarea\n",
    "Les propongo, definir una función llamada `clean_text`, la cual reciba un texto y como salida obtengamos un equivalente al mismo pero procesado.\n",
    "\n",
    "Según lo visto en clases, algo que no debería faltar es:\n",
    "- pasar a minúscula\n",
    "- remover stopwords\n",
    "- limpiar caracteres sueltos o de poco interés.\n",
    "\n",
    "Como pista, no hace falta usar regex complejas, pueden valerse de las bondades que ofrece el lenguaje. Como futuros datascience, investigar y encontrar otras soluciones es una parte clave y del diario de sus tareas.\n",
    "\n",
    "Muchas suerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(corpus):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
